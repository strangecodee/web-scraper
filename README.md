<!-- ================= HEADER ================= -->
<p align="center">
  <a href="https://www.linkedin.com/in/annuragmaurya/" target="_blank">
    <img src="https://img.icons8.com/color/48/000000/linkedin.png" width="40"/>
  </a>
  <a href="https://github.com/strangecodee" target="_blank">
    <img src="https://img.icons8.com/fluency/48/github.png" width="40"/>
  </a>
  <a href="mailto:annu.exe@gmail.com" target="_blank">
    <img src="https://img.icons8.com/color/48/gmail-new.png" width="40"/>
  </a>
</p>

---

# ğŸ‘‹ Hi, I'm Anurag Maurya  
ğŸ’» Aspiring Full-Stack Developer | â˜ï¸ Cloud & DevOps Enthusiast  

---

# ğŸ•¸ï¸ Web Scraper â€“ Automated Due Amount Extractor  

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg?logo=python)  
![Selenium](https://img.shields.io/badge/Selenium-Automation-green.svg?logo=selenium)  
![Status](https://img.shields.io/badge/Status-Active-success.svg)  

---

## ğŸ“Œ Overview  

This project is a **web scraping automation tool** built with **Python + Selenium**.  
It extracts **due amounts** from a given list of URLs and stores the results into an **Excel file** using **Pandas**.  

ğŸ”¹ Perfect for automating repetitive financial checks.  
ğŸ”¹ Reads input URLs from Google Sheets or Excel.  
ğŸ”¹ Writes scraped data back to an output sheet.  

---

## âš¡ Features  

- âœ… Automates **login & navigation**  
- âœ… Extracts **due amount** values  
- âœ… Saves results to **Excel/CSV**  
- âœ… Supports **multi-threading** for speed  
- âœ… Error handling with logging  

---

## ğŸš€ Tech Stack  

- **Language**: Python ğŸ  
- **Automation**: Selenium  
- **Data Handling**: Pandas  
- **Output**: Excel / CSV  

---

## ğŸ“‚ Project Structure
- ğŸ“œ`enhanced_scrape_dues.py` â†’ Main script  
- ğŸ“œ`requirements.txt` â†’ Python dependencies  
- ğŸ“œ`README.md` â†’ Project documentation  
- ğŸ“œ`output.xlsx` â†’ (Generated) Output file with scraped data  


---

## âš¡ Setup Instructions  

### 1ï¸âƒ£ Clone the repository  
```bash
git clone https://github.com/strangecodee/web-scraper.git
cd web-scraper
```
### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
# Activate it
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate
```
 ### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### â–¶ï¸ Running the Script
```bash
python enhanced_scrape_dues.py
```

### The script will open Chrome using Selenium

- Visit all URLs (from your list / Google Sheet)

- Extract due amounts

- Save results to output.xlsx

## ğŸ“Š Example Output (Excel)

After running the script, an `output.xlsx` file will be generated.  
It contains the scraped results in the following format:

## ğŸ“Š Example Output (Excel)

After running the scraper, an `output.xlsx` file will be generated with the following structure:

| Portfolio's | Agent            | Mtd | Loan ID      | Link                                                                                                                                     | Due Amount |
|-------------|------------------|-----|--------------|------------------------------------------------------------------------------------------------------------------------------------------|------------|
| MONEY VIEW  | Surabhi (MV NPA) |     | 1.03461E+11  | [Open](https://moneyview.whizdm.com/payment/init?l=ff808081925184b40192550850906f73&paymentIntent=dues&source=web&originSource=agency)  | 8059       |
| MONEY VIEW  | Surabhi (MV NPA) |     | 1.49486E+11  | [Open](https://moneyview.whizdm.com/payment/init?l=ff808081901f526f019021881aeb5bce&paymentIntent=dues&source=web&originSource=agency)  | 19420      |
| MONEY VIEW  | Surabhi (MV NPA) |     | 1.03091E+11  | [Open](https://moneyview.whizdm.com/payment/init?l=ff8080818fed91e7018fef1521e249e4&paymentIntent=dues&source=web&originSource=agency)  | 35516      |
| MONEY VIEW  | Surabhi (MV NPA) |     | 1.39459E+11  | [Open](https://moneyview.whizdm.com/payment/init?l=ff8080819208c605019209b12d49609c&paymentIntent=dues&source=web&originSource=agency)  | 8112       |

---
### â­ Contributing

Contributions are welcome!
If you'd like to improve this scraper, feel free to fork the repo and submit a pull request.

---
### ğŸ“œ License

This project is licensed under the MIT License â€“ feel free to use and modify it.

---

<!-- ================= FOOTER ================= -->
<p align="center">
  Made with ğŸ’» by <b>Anurag Maurya</b>  
  <br/>
  <a href="https://www.linkedin.com/in/annuragmaurya/" target="_blank">
    <img src="https://img.icons8.com/color/48/000000/linkedin.png" width="30"/>
  </a>
  <a href="https://github.com/strangecodee" target="_blank">
    <img src="https://img.icons8.com/fluency/48/github.png" width="30"/>
  </a>
  <a href="mailto:annu.exe@gmail.com" target="_blank">
    <img src="https://img.icons8.com/color/48/gmail-new.png" width="30"/>
  </a>
</p>


